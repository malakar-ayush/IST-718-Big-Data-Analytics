{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51bf8a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2J\n",
      "\n",
      "\n",
      "           # #                 # #                 # #      \n",
      "           # #                 # #                 # #      \n",
      "          $$$$$               $$$$$               $$$$$     \n",
      "        $$ # # $$           $$ # # $$           $$ # # $$   \n",
      "       $$$ # #             $$$ # #             $$$ # #      \n",
      "        $$$# #              $$$# #              $$$# #      \n",
      "          $$$#                $$$#                $$$#      \n",
      "           #$$$                #$$$                #$$$     \n",
      "           # #$$$              # #$$$              # #$$$   \n",
      "           # # $$$             # # $$$             # # $$$  \n",
      "       $$$ # #  $$$$       $$$ # #  $$$$       $$$ # #  $$$$\n",
      "        $$$# # $$$$         $$$# # $$$$         $$$# # $$$$ \n",
      "          $$$$$$$             $$$$$$$             $$$$$$$   \n",
      "           # #                 # #                 # #      \n",
      "           # #                 # #                 # #      \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "#                      Project : Predicting Stock Price\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# Clear Screen\n",
    "# \n",
    "print(chr(27) + \"[2J\")\n",
    "\n",
    "\n",
    "# Banner\n",
    "#\n",
    "print('')\n",
    "print('')\n",
    "print('           # #                 # #                 # #      ')\n",
    "print('           # #                 # #                 # #      ')\n",
    "print('          $$$$$               $$$$$               $$$$$     ')\n",
    "print('        $$ # # $$           $$ # # $$           $$ # # $$   ')\n",
    "print('       $$$ # #             $$$ # #             $$$ # #      ')\n",
    "print('        $$$# #              $$$# #              $$$# #      ')\n",
    "print('          $$$#                $$$#                $$$#      ')\n",
    "print('           #$$$                #$$$                #$$$     ')\n",
    "print('           # #$$$              # #$$$              # #$$$   ')\n",
    "print('           # # $$$             # # $$$             # # $$$  ')\n",
    "print('       $$$ # #  $$$$       $$$ # #  $$$$       $$$ # #  $$$$')\n",
    "print('        $$$# # $$$$         $$$# # $$$$         $$$# # $$$$ ')\n",
    "print('          $$$$$$$             $$$$$$$             $$$$$$$   ')\n",
    "print('           # #                 # #                 # #      ')\n",
    "print('           # #                 # #                 # #      ')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be4adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9ccf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Phases:Project : Predicting Stock Price\n",
      "INFO:Phases:Phases Logger Init\n",
      "INFO:Details:Project : Predicting Stock Price\n",
      "INFO:Details:Details Logger Init\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Enabling Logging\n",
    "# ==============================================================================\n",
    "\n",
    "import logging\n",
    "\n",
    "# Logger Settings:\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "def setup_logger(name, log_file, level=logging.INFO):\n",
    "    \"\"\"To setup as many loggers as you want\"\"\"\n",
    "    handler = logging.FileHandler(log_file)        \n",
    "    handler.setFormatter(formatter)\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "# Phases Logger\n",
    "phases_logger_file = 'PostProc_log_phases.log'\n",
    "os.system('rm -rf '+ phases_logger_file)\n",
    "phases_logger = setup_logger('Phases', phases_logger_file)\n",
    "phases_logger.info('Project : Predicting Stock Price')\n",
    "phases_logger.info('Phases Logger Init')\n",
    "\n",
    "# Details Logger\n",
    "details_logger_file = 'PostProc_log_details.log'\n",
    "os.system('rm -rf '+ details_logger_file)\n",
    "details_logger = setup_logger('Details', details_logger_file)\n",
    "details_logger.info('Project : Predicting Stock Price')\n",
    "details_logger.info('Details Logger Init')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "647ab6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Phases:Importing Basic Packages : Start\n",
      "INFO:Details:Import : re\n",
      "INFO:Details:Import : os\n",
      "INFO:Details:Import : sys\n",
      "INFO:Phases:Importing Basic Packages : End\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Importing Basic Packages\n",
    "# ==============================================================================\n",
    "\n",
    "phases_logger.info('Importing Basic Packages : Start')\n",
    "\n",
    "details_logger.info('Import : re')\n",
    "import re\n",
    "\n",
    "details_logger.info('Import : os')\n",
    "import os\n",
    "\n",
    "details_logger.info('Import : sys')\n",
    "import sys\n",
    "\n",
    "phases_logger.info('Importing Basic Packages : End')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d651d292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Phases:Importing Project Specific Packages : Start\n",
      "INFO:Details:Import : inline\n",
      "INFO:Details:Import : pandas\n",
      "INFO:Details:Import : numpy\n",
      "INFO:Details:Import : scipy\n",
      "INFO:Details:Import : patsy\n",
      "INFO:Details:Import : seaborn\n",
      "INFO:Details:Import : queue\n",
      "INFO:Details:Import : threading\n",
      "INFO:Details:Import : time\n",
      "INFO:Details:Import : sklearn\n",
      "INFO:Details:Import : statsmodels\n",
      "INFO:Details:Import : pmdarima\n",
      "INFO:Details:Import : zipfile\n",
      "INFO:Phases:Project Specific Package Load : End\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Importing Project Specific Packages\n",
    "# ==============================================================================\n",
    "\n",
    "phases_logger.info('Importing Project Specific Packages : Start')\n",
    "\n",
    "# Identifying Customer Targets (Python)\n",
    "details_logger.info('Import : inline')\n",
    "%matplotlib inline\n",
    "\n",
    "# import packages for text processing and machine learning\n",
    "details_logger.info('Import : pandas')\n",
    "import pandas as pd  # DataFrame structure and operations\n",
    "from pandas.plotting import scatter_matrix  # scatter plot matrix\n",
    "\n",
    "details_logger.info('Import : numpy')\n",
    "import numpy as np  # arrays and numerical processing\n",
    "import matplotlib.pyplot as plt  # 2D plotting\n",
    "\n",
    "details_logger.info('Import : scipy')\n",
    "from scipy.stats import uniform  # for training-and-test split\n",
    "\n",
    "details_logger.info('Import : patsy')\n",
    "import patsy  # translate model specification into design matrices\n",
    "\n",
    "details_logger.info('Import : seaborn')\n",
    "import seaborn as sns  # PROVIDES TRELLIS AND SMALL MULTIPLE PLOTTING\n",
    "\n",
    "# import user-defined module\n",
    "# details_logger.info('import evaluate_classifier')\n",
    "# import evaluate_classifier as eval\n",
    "\n",
    "# FOLLOWING PACKAGE BEST IMPORTED AND INSTALLED VIA CONDA PROMPT\n",
    "# conda install -c conda-forge mlxtend\n",
    "\n",
    "# Association Rules Mining\n",
    "# details_logger.info('import mlxtend')\n",
    "# from mlxtend.frequent_patterns import apriori            # EASY ASSOCIATION RULES PACKAGE FROM RABST\n",
    "# from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "details_logger.info('Import : queue')\n",
    "from queue import Queue\n",
    "\n",
    "details_logger.info('Import : threading')\n",
    "import threading\n",
    "\n",
    "details_logger.info('Import : time')\n",
    "import time\n",
    "\n",
    "details_logger.info('Import : sklearn')\n",
    "from sklearn.tree import DecisionTreeRegressor  # machine learning tree\n",
    "from sklearn.ensemble import RandomForestRegressor # ensemble method\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "details_logger.info('Import : statsmodels')\n",
    "import statsmodels.api as sm  # logistic regression\n",
    "import statsmodels.formula.api as smf  # R-like model specification\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "details_logger.info('Import : pmdarima')\n",
    "import pmdarima as pm\n",
    "\n",
    "details_logger.info('Import : zipfile')\n",
    "import zipfile\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "phases_logger.info('Project Specific Package Load : End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af8fa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Details:PWD: /Users/niranjanjuvekar/MyStuff/Education_Niranjan/Data_Science_Syracuse_University/12_IST_718/Project/devel_014/predictingstockprice\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Present Working Directory\n",
    "# ==============================================================================\n",
    "\n",
    "# This will print the current directory : Debugging purposes\n",
    "details_logger.info('PWD: ' + os.getcwd())\n",
    "PWD = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7d52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Information\n",
    "# ==============================================================================\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Following should be your tree such that the link 'stock_market_data' points to\n",
    "# actual directory 'stock_market_data' that is 2 directories above\n",
    "\n",
    "# \n",
    "# MY_PROJECT_DIR\n",
    "# ├── BITBUCKET_CHECKOUT_DIR_000\n",
    "# │   └── predictingstockprice\n",
    "# │       ├── OtherTSVs\n",
    "# │       ├── lib\n",
    "# │       ├── stock_market_data -> ../../stock_market_data\n",
    "# │       └── CSV -> ../../CSV\n",
    "# ├── stock_market_data\n",
    "# │   ├── forbes2000\n",
    "# │   │   ├── csv\n",
    "# │   │   └── json\n",
    "# │   ├── nasdaq\n",
    "# │   │   ├── csv\n",
    "# │   │   └── json\n",
    "# │   ├── nyse\n",
    "# │   │   ├── csv\n",
    "# │   │   └── json\n",
    "# │   └── sp500\n",
    "# │       ├── csv\n",
    "# │       └── json\n",
    "# └── CSV\n",
    "#     ├── AdjustedClose_df.csv.zip\n",
    "#     ├── Close_df.csv.zip\n",
    "#     ├── High_df.csv.zip\n",
    "#     ├── Low_df.csv.zip\n",
    "#     └── Open_df.csv.zip\n",
    "# \n",
    "\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d81a28b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Phases:User Settings : Start\n",
      "INFO:Details:User Settings:\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# User Settings\n",
    "# ==============================================================================\n",
    "\n",
    "phases_logger.info('User Settings : Start')\n",
    "\n",
    "# Logging User Settings:\n",
    "#\n",
    "details_logger.info('User Settings:')\n",
    "\n",
    "\n",
    "## Uncomment following to override the stock_market_data_path\n",
    "\n",
    "# USER_SETTING_HERE\n",
    "# \n",
    "# If the tree structure thing does not work for you, you may have to use the following paths instead:\n",
    "## Ayush:\n",
    "# stock_market_data_path = 'Add_your_path_here'\n",
    "## CB:\n",
    "# stock_market_data_path = '/Users/cbgarrett/Documents/ist718project/stock_market_data'\n",
    "## Richard:\n",
    "# stock_market_data_path = 'Add_your_path_here'\n",
    "## Niranjan:\n",
    "# stock_market_data_path = '/Users/niranjanjuvekar/MyStuff/Education_Niranjan/Data_Science_Syracuse_University/12_IST_718/Project/stock_market_data'\n",
    "\n",
    "\n",
    "\n",
    "# USER_SETTING_HERE\n",
    "# Select the dataFrame(s) to be used\n",
    "# \n",
    "USE_Open_df          = True\n",
    "USE_Close_df         = True\n",
    "USE_Low_df           = True\n",
    "USE_High_df          = True\n",
    "USE_Volume_df        = False\n",
    "USE_AdjustedClose_df = False\n",
    "\n",
    "\n",
    "# USER_SETTING_HERE\n",
    "# Select the dataFrame(s) to be used\n",
    "# \n",
    "USE_RNN_FORECAST     = True\n",
    "USE_LSTM_FORECAST    = True\n",
    "USE_ARIMA_FORECAST   = True\n",
    "\n",
    "\n",
    "# USER_SETTING_HERE\n",
    "# Once the dataFrame has been processed, we can\n",
    "# write it to the disk in TSV or CSV format\n",
    "#\n",
    "write_CSV = False\n",
    "write_TSV = False\n",
    "\n",
    "\n",
    "# USER_SETTINGS_HERE\n",
    "# Maximum number of parallel threads to be spawned\n",
    "#\n",
    "# maxThreads = 2\n",
    "maxThreads = 6\n",
    "\n",
    "\n",
    "# USER_SETTING_HERE\n",
    "# Number of models to be run\n",
    "#\n",
    "N = 410\n",
    "# N = 400\n",
    "# N = 200\n",
    "# N = 100\n",
    "# N = 50\n",
    "# N = 30\n",
    "# N = 24\n",
    "# N = 1 # Run only one model (Default)\n",
    "\n",
    "\n",
    "# USER_SETTINGS_HERE\n",
    "# Number of forecasting periods (Unit : Business days)\n",
    "#\n",
    "n_periods = 30\n",
    "\n",
    "\n",
    "# USER_SETTING_HERE\n",
    "# Last date with sampled values beyond which the dataFrame / CSV would be empty\n",
    "LastSampledDate = '24/10/2022'\n",
    "\n",
    "\n",
    "# USER_SETTING_HERE\n",
    "# Output Dir\n",
    "outputDir = 'Output'\n",
    "\n",
    "# USER_SETTING_HERE\n",
    "# Temporary Dir\n",
    "tempDir = 'temp'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57cc2fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Details:User Setting : stock_market_data_path = /Users/niranjanjuvekar/MyStuff/Education_Niranjan/Data_Science_Syracuse_University/12_IST_718/Project/stock_market_data\n",
      "INFO:Details:User Setting : USE_RNN_FORECAST = True\n",
      "INFO:Details:User Setting : USE_LSTM_FORECAST = True\n",
      "INFO:Details:User Setting : USE_ARIMA = True\n",
      "INFO:Details:User Setting : USE_Open_df = True\n",
      "INFO:Details:User Setting : USE_Close_df = True\n",
      "INFO:Details:User Setting : USE_Low_df = True\n",
      "INFO:Details:User Setting : USE_High_df = True\n",
      "INFO:Details:User Setting : write_CSV = False\n",
      "INFO:Details:User Setting : write_TSV = False\n",
      "INFO:Details:User Setting : Last sampled date = 24/10/2022\n",
      "INFO:Details:User Setting : Number of models    = 410\n",
      "INFO:Details:User Setting : Maximum Threads     = 6\n",
      "INFO:Details:User Setting : Forecast Samples    = 30\n",
      "INFO:Details:User Setting : Temporary Directory = False\n",
      "INFO:Phases:User Settings : End\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Processing and Logging the User Settings\n",
    "# \n",
    "\n",
    "\n",
    "# Using stock_market_data link in the current directory\n",
    "# stock_market_data -> ../../stock_market_data\n",
    "#\n",
    "stock_market_data_path = os.path.realpath('stock_market_data')\n",
    "details_logger.info('User Setting : stock_market_data_path = ' + stock_market_data_path)\n",
    "\n",
    "forecastModels = []\n",
    "if USE_RNN_FORECAST:\n",
    "    details_logger.info('User Setting : USE_RNN_FORECAST = True')\n",
    "    forecastModels.append('RNN')\n",
    "if USE_LSTM_FORECAST:\n",
    "    details_logger.info('User Setting : USE_LSTM_FORECAST = True')\n",
    "    forecastModels.append('LSTM')\n",
    "if USE_ARIMA_FORECAST:\n",
    "    details_logger.info('User Setting : USE_ARIMA = True')\n",
    "    forecastModels.append('ARIMA')\n",
    "\n",
    "if len(forecastModels) < 2:\n",
    "    details_logger.info('Less than 2 models! Nothing to compare. Exiting')\n",
    "    sys.exit()\n",
    "    \n",
    "\n",
    "dfList = []\n",
    "if USE_Open_df:\n",
    "    dfList.append('Open')\n",
    "    \n",
    "if USE_Close_df:\n",
    "    dfList.append('Close')\n",
    "\n",
    "if USE_Low_df:\n",
    "    dfList.append('Low')\n",
    "    \n",
    "if USE_High_df:\n",
    "    dfList.append('High')\n",
    "    \n",
    "if USE_Volume_df:\n",
    "    dfList.append('Volume')\n",
    "    \n",
    "if USE_AdjustedClose_df:\n",
    "    dfList.append('AdjustedClose')\n",
    "\n",
    "\n",
    "\n",
    "dfFileList = []\n",
    "\n",
    "if USE_Open_df:\n",
    "    details_logger.info('User Setting : USE_Open_df = True')\n",
    "    if USE_RNN_FORECAST:\n",
    "        dfFileList.append('RNN_forecast_Opendf.csv')\n",
    "    if USE_LSTM_FORECAST:\n",
    "        dfFileList.append('LSTM_forecast_Opendf.csv')\n",
    "    if USE_ARIMA_FORECAST:\n",
    "        dfFileList.append('ARIMA_forecast_Opendf.csv')\n",
    "\n",
    "if USE_Close_df:\n",
    "    details_logger.info('User Setting : USE_Close_df = True')\n",
    "    if USE_RNN_FORECAST:\n",
    "        dfFileList.append('RNN_forecast_Closedf.csv')\n",
    "    if USE_LSTM_FORECAST:\n",
    "        dfFileList.append('LSTM_forecast_Closedf.csv')\n",
    "    if USE_ARIMA_FORECAST:\n",
    "        dfFileList.append('ARIMA_forecast_Closedf.csv')\n",
    "\n",
    "if USE_Low_df:\n",
    "    details_logger.info('User Setting : USE_Low_df = True')\n",
    "    if USE_RNN_FORECAST:\n",
    "        dfFileList.append('RNN_forecast_Lowdf.csv')\n",
    "    if USE_LSTM_FORECAST:\n",
    "        dfFileList.append('LSTM_forecast_Lowdf.csv')\n",
    "    if USE_ARIMA_FORECAST:\n",
    "        dfFileList.append('ARIMA_forecast_Lowdf.csv')\n",
    "    \n",
    "if USE_High_df:\n",
    "    details_logger.info('User Setting : USE_High_df = True')\n",
    "    if USE_RNN_FORECAST:\n",
    "        dfFileList.append('RNN_forecast_Highdf.csv')\n",
    "    if USE_LSTM_FORECAST:\n",
    "        dfFileList.append('LSTM_forecast_Highdf.csv')\n",
    "    if USE_ARIMA_FORECAST:\n",
    "        dfFileList.append('ARIMA_forecast_Highdf.csv')\n",
    "    \n",
    "if USE_Volume_df:\n",
    "    details_logger.info('User Setting : USE_Volume_df = True')\n",
    "    if USE_RNN_FORECAST:\n",
    "        dfFileList.append('RNN_forecast_Volumedf.csv')\n",
    "    if USE_LSTM_FORECAST:\n",
    "        dfFileList.append('LSTM_forecast_Volumedf.csv')\n",
    "    if USE_ARIMA_FORECAST:\n",
    "        dfFileList.append('ARIMA_forecast_Volumedf.csv')\n",
    "    \n",
    "if USE_AdjustedClose_df:\n",
    "    details_logger.info('User Setting : USE_AdjustedClose_df = True')\n",
    "    if USE_RNN_FORECAST:\n",
    "        dfFileList.append('RNN_forecast_AdjustedClosedf.csv')\n",
    "    if USE_LSTM_FORECAST:\n",
    "        dfFileList.append('LSTM_forecast_AdjustedClosedf.csv')\n",
    "    if USE_ARIMA_FORECAST:\n",
    "        dfFileList.append('ARIMA_forecast_AdjustedClosedf.csv')\n",
    "\n",
    "        \n",
    "    \n",
    "details_logger.info('User Setting : write_CSV = ' + str(write_CSV))\n",
    "details_logger.info('User Setting : write_TSV = ' + str(write_TSV))\n",
    "\n",
    "details_logger.info('User Setting : Last sampled date = ' + LastSampledDate)\n",
    "\n",
    "details_logger.info('User Setting : Number of models    = ' + str(N))\n",
    "details_logger.info('User Setting : Maximum Threads     = ' + str(maxThreads))\n",
    "details_logger.info('User Setting : Forecast Samples    = ' + str(n_periods))\n",
    "details_logger.info('User Setting : Temporary Directory = ' + str(write_CSV))\n",
    "\n",
    "phases_logger.info('User Settings : End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6cf26ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# ==============================================================================\\n# Unzip required dataFrame files\\n# ==============================================================================\\n\\nfor file in dfFileList:\\n    with zipfile.ZipFile(PWD+'/CSV/'+file+'_df.csv.zip', 'r') as zip_ref:\\n        zip_ref.extractall(PWD+'/CSV/')\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# ==============================================================================\n",
    "# Unzip required dataFrame files\n",
    "# ==============================================================================\n",
    "\n",
    "for file in dfFileList:\n",
    "    with zipfile.ZipFile(PWD+'/CSV/'+file+'_df.csv.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(PWD+'/CSV/')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eab0e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Phases:Initialize for Models Generation : Start\n",
      "INFO:Phases:Initialize for Models Generation : End\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Initialize variables for model generation\n",
    "# ==============================================================================\n",
    "\n",
    "phases_logger.info('Initialize for Models Generation : Start')\n",
    "\n",
    "# Threads Dictionary\n",
    "t = {}\n",
    "\n",
    "# Queue Settings\n",
    "q = Queue(maxsize = maxThreads)\n",
    "\n",
    "# Model Dictionary\n",
    "model = {}\n",
    "\n",
    "nan_value = float(\"NaN\")\n",
    "\n",
    "\n",
    "# Model Generation Tracker : Keeps track of what models are built and being built\n",
    "modelGenTracker = []\n",
    "modelGenPointer = len(modelGenTracker) - 1\n",
    "\n",
    "phases_logger.info('Initialize for Models Generation : End')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b9c4a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Create a fresh Temporary Directory\n",
    "# ==============================================================================\n",
    "\n",
    "tempDirExists = os.path.exists(tempDir)\n",
    "\n",
    "if tempDirExists:\n",
    "    import shutil\n",
    "    shutil.rmtree(tempDir)\n",
    "os.makedirs(tempDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdc25841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Transposed dataframes to be written\n",
    "# ==============================================================================\n",
    "\n",
    "for dfFile in dfFileList:\n",
    "    df = pd.read_csv(PWD+'/'+outputDir+'/'+dfFile, sep='\\t', header='infer')\n",
    "    df = df.set_index('Unnamed: 0')\n",
    "    df = df.transpose()\n",
    "    df.to_csv(PWD+'/'+tempDir+'/'+dfFile, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b973d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64c332a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Models Composit - by Values\n",
    "# ==============================================================================\n",
    "\n",
    "for dfName in dfList:\n",
    "\n",
    "    df1 = pd.read_csv(PWD+'/'+tempDir+'/'+'RNN_forecast_'+dfName+'df.csv', sep='\\t', header='infer')\n",
    "    df2 = pd.read_csv(PWD+'/'+tempDir+'/'+'LSTM_forecast_'+dfName+'df.csv', sep='\\t', header='infer')\n",
    "    df3 = pd.read_csv(PWD+'/'+tempDir+'/'+'ARIMA_forecast_'+dfName+'df.csv', sep='\\t', header='infer')\n",
    "\n",
    "    df1_columns = df1.columns\n",
    "    df2_columns = df2.columns\n",
    "    df3_columns = df3.columns\n",
    "\n",
    "    commonTickerList = []\n",
    "    for i in df1_columns :\n",
    "        if i in df2_columns :\n",
    "            if i in df3_columns :\n",
    "                if i != 'Unnamed: 0':\n",
    "                    commonTickerList.append(i)\n",
    "\n",
    "    for columnName in commonTickerList:\n",
    "        a1 = df1.loc[:, columnName][:30].to_numpy()\n",
    "        a2 = df2.loc[:, columnName][:30].to_numpy()\n",
    "        a3 = df3.loc[:, columnName][:30].to_numpy()\n",
    "        newdf = pd.DataFrame()\n",
    "        newdf['Business Days'] = pd.Series(range(1,31,1))\n",
    "        newdf['RNN']=pd.Series(a1)\n",
    "        newdf['LSTM']=pd.Series(a2)\n",
    "        newdf['ARIMA']=pd.Series(a3)\n",
    "        newdf.to_csv(PWD+'/'+tempDir+'/ModelsComposit_'+columnName+'_'+dfName+'.csv', sep='\\t', encoding='utf-8')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d05879d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Values Composit - by Models\n",
    "# ==============================================================================\n",
    "\n",
    "for forecastModel in forecastModels:\n",
    "    \n",
    "    # for dfName in dfList:\n",
    "    df1 = pd.read_csv(PWD+'/'+tempDir+'/'+forecastModel+'_forecast_Opendf.csv', sep='\\t', header='infer')\n",
    "    df2 = pd.read_csv(PWD+'/'+tempDir+'/'+forecastModel+'_forecast_Closedf.csv', sep='\\t', header='infer')\n",
    "    df3 = pd.read_csv(PWD+'/'+tempDir+'/'+forecastModel+'_forecast_Highdf.csv', sep='\\t', header='infer')\n",
    "    df4 = pd.read_csv(PWD+'/'+tempDir+'/'+forecastModel+'_forecast_Lowdf.csv', sep='\\t', header='infer')\n",
    "\n",
    "    df1_columns = df1.columns\n",
    "    df2_columns = df2.columns\n",
    "    df3_columns = df3.columns\n",
    "    df4_columns = df4.columns\n",
    "\n",
    "    commonTickerList = []\n",
    "    for i in df1_columns :\n",
    "        if i in df2_columns :\n",
    "            if i in df3_columns :\n",
    "                if i in df4_columns :\n",
    "                    if i != 'Unnamed: 0':\n",
    "                        commonTickerList.append(i)\n",
    "\n",
    "    for columnName in commonTickerList:\n",
    "        a1 = df1.loc[:, columnName][:30].to_numpy()\n",
    "        a2 = df2.loc[:, columnName][:30].to_numpy()\n",
    "        a3 = df3.loc[:, columnName][:30].to_numpy()\n",
    "        a4 = df4.loc[:, columnName][:30].to_numpy()\n",
    "\n",
    "        newdf = pd.DataFrame()\n",
    "        newdf['Business Days'] = pd.Series(range(1,31,1))\n",
    "        newdf['Open']=pd.Series(a1)\n",
    "        newdf['Close']=pd.Series(a2)\n",
    "        newdf['High']=pd.Series(a3)\n",
    "        newdf['Low']=pd.Series(a4)\n",
    "        newdf.to_csv(PWD+'/'+tempDir+'/ValuesComposit_'+columnName+'_'+forecastModel+'.csv', sep='\\t', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1b13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8206279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48fc33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(PWD+'/'+tempDir+'/ARIMA_forecast_Opendf.csv', sep='\\t', header='infer')\n",
    "df2 = pd.read_csv(PWD+'/'+tempDir+'/ARIMA_forecast_Closedf.csv', sep='\\t', header='infer')\n",
    "df3 = pd.read_csv(PWD+'/'+tempDir+'/ARIMA_forecast_Highdf.csv', sep='\\t', header='infer')\n",
    "df4 = pd.read_csv(PWD+'/'+tempDir+'/ARIMA_forecast_Lowdf.csv', sep='\\t', header='infer')\n",
    "\n",
    "df1_columns = df1.columns\n",
    "df2_columns = df2.columns\n",
    "df3_columns = df3.columns\n",
    "df4_columns = df4.columns\n",
    "\n",
    "commonTickerList = []\n",
    "for i in df1_columns :\n",
    "    if i in df2_columns :\n",
    "        if i in df3_columns :\n",
    "            if i in df4_columns :\n",
    "                if i != 'Unnamed: 0':\n",
    "                    commonTickerList.append(i)\n",
    "\n",
    "# print(commonTickerList)\n",
    "# print()\n",
    "# print(len(commonTickerList))\n",
    "\n",
    "ARIMA_Open_arr  = df1.iloc[0].iloc[:] # 1 Day Forecast Open\n",
    "ARIMA_Close_arr = df2.iloc[0].iloc[:] # 1 Day Forecast Close\n",
    "ARIMA_High_arr  = df3.iloc[0].iloc[:] # 1 Day Forecast High\n",
    "ARIMA_Low_arr   = df4.iloc[0].iloc[:] # 1 Day Forecast Low\n",
    "\n",
    "ARIMA_BUY_DayTrade = ARIMA_High_arr / ARIMA_Low_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c44c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(PWD+'/'+tempDir+'/LSTM_forecast_Opendf.csv', sep='\\t', header='infer')\n",
    "df2 = pd.read_csv(PWD+'/'+tempDir+'/LSTM_forecast_Closedf.csv', sep='\\t', header='infer')\n",
    "df3 = pd.read_csv(PWD+'/'+tempDir+'/LSTM_forecast_Highdf.csv', sep='\\t', header='infer')\n",
    "df4 = pd.read_csv(PWD+'/'+tempDir+'/LSTM_forecast_Lowdf.csv', sep='\\t', header='infer')\n",
    "\n",
    "df1_columns = df1.columns\n",
    "df2_columns = df2.columns\n",
    "df3_columns = df3.columns\n",
    "df4_columns = df4.columns\n",
    "\n",
    "commonTickerList = []\n",
    "for i in df1_columns :\n",
    "    if i in df2_columns :\n",
    "        if i in df3_columns :\n",
    "            if i in df4_columns :\n",
    "                if i != 'Unnamed: 0':\n",
    "                    commonTickerList.append(i)\n",
    "\n",
    "# print(commonTickerList)\n",
    "# print()\n",
    "# print(len(commonTickerList))\n",
    "\n",
    "LSTM_Open_arr  = df1.iloc[0].iloc[:] # 1 Day Forecast Open\n",
    "LSTM_Close_arr = df2.iloc[0].iloc[:] # 1 Day Forecast Close\n",
    "LSTM_High_arr  = df3.iloc[0].iloc[:] # 1 Day Forecast High\n",
    "LSTM_Low_arr   = df4.iloc[0].iloc[:] # 1 Day Forecast Low\n",
    "\n",
    "LSTM_BUY_DayTrade = LSTM_High_arr / LSTM_Low_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f060e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(PWD+'/'+tempDir+'/RNN_forecast_Opendf.csv', sep='\\t', header='infer')\n",
    "df2 = pd.read_csv(PWD+'/'+tempDir+'/RNN_forecast_Closedf.csv', sep='\\t', header='infer')\n",
    "df3 = pd.read_csv(PWD+'/'+tempDir+'/RNN_forecast_Highdf.csv', sep='\\t', header='infer')\n",
    "df4 = pd.read_csv(PWD+'/'+tempDir+'/RNN_forecast_Lowdf.csv', sep='\\t', header='infer')\n",
    "\n",
    "df1_columns = df1.columns\n",
    "df2_columns = df2.columns\n",
    "df3_columns = df3.columns\n",
    "df4_columns = df4.columns\n",
    "\n",
    "commonTickerList = []\n",
    "for i in df1_columns :\n",
    "    if i in df2_columns :\n",
    "        if i in df3_columns :\n",
    "            if i in df4_columns :\n",
    "                if i != 'Unnamed: 0':\n",
    "                    commonTickerList.append(i)\n",
    "\n",
    "# print(commonTickerList)\n",
    "# print()\n",
    "# print(len(commonTickerList))\n",
    "\n",
    "RNN_Open_arr  = df1.iloc[0].iloc[:] # 1 Day Forecast Open\n",
    "RNN_Close_arr = df2.iloc[0].iloc[:] # 1 Day Forecast Close\n",
    "RNN_High_arr  = df3.iloc[0].iloc[:] # 1 Day Forecast High\n",
    "RNN_Low_arr   = df4.iloc[0].iloc[:] # 1 Day Forecast Low\n",
    "\n",
    "RNN_BUY_DayTrade = RNN_High_arr / RNN_Low_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4628510",
   "metadata": {},
   "outputs": [],
   "source": [
    "Composite = ARIMA_BUY_DayTrade.to_frame()\n",
    "Composite.columns = ['ARIMA']\n",
    "Composite['LSTM'] = LSTM_BUY_DayTrade\n",
    "Composite['RNN'] = RNN_BUY_DayTrade\n",
    "Composite = Composite.dropna()\n",
    "\n",
    "Composite['ARIMA_BUY'] = Composite['ARIMA'] > 1\n",
    "Composite['LSTM_BUY']  = Composite['LSTM'] > 1\n",
    "Composite['RNN_BUY']   = Composite['RNN'] > 1\n",
    "\n",
    "Composite['ARIMA_SELL'] = Composite['ARIMA'] < 1\n",
    "Composite['LSTM_SELL']  = Composite['LSTM'] < 1\n",
    "Composite['RNN_SELL']   = Composite['RNN'] < 1\n",
    "\n",
    "Composite['BUY_SELL'] = Composite['ARIMA'] + Composite['LSTM'] + Composite['RNN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27ed5050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARIMA</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>RNN</th>\n",
       "      <th>ARIMA_BUY</th>\n",
       "      <th>LSTM_BUY</th>\n",
       "      <th>RNN_BUY</th>\n",
       "      <th>ARIMA_SELL</th>\n",
       "      <th>LSTM_SELL</th>\n",
       "      <th>RNN_SELL</th>\n",
       "      <th>BUY_SELL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UAL</th>\n",
       "      <td>1.033117</td>\n",
       "      <td>1.035048</td>\n",
       "      <td>1.035048</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.103214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVR</th>\n",
       "      <td>1.020365</td>\n",
       "      <td>1.021686</td>\n",
       "      <td>1.021686</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.063736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISRG</th>\n",
       "      <td>1.012360</td>\n",
       "      <td>1.015842</td>\n",
       "      <td>1.015842</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.044043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TROW</th>\n",
       "      <td>1.019398</td>\n",
       "      <td>1.019575</td>\n",
       "      <td>1.019575</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.058549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLSN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECL</th>\n",
       "      <td>1.020098</td>\n",
       "      <td>1.022426</td>\n",
       "      <td>1.022426</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.064950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBAY</th>\n",
       "      <td>1.028219</td>\n",
       "      <td>1.027660</td>\n",
       "      <td>1.027660</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.083538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBUX</th>\n",
       "      <td>1.059919</td>\n",
       "      <td>1.060984</td>\n",
       "      <td>1.060984</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.181887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DPZ</th>\n",
       "      <td>1.022884</td>\n",
       "      <td>1.022898</td>\n",
       "      <td>1.022898</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.068680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRE</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ARIMA      LSTM       RNN  ARIMA_BUY  LSTM_BUY  RNN_BUY  ARIMA_SELL  \\\n",
       "UAL   1.033117  1.035048  1.035048       True      True     True       False   \n",
       "NVR   1.020365  1.021686  1.021686       True      True     True       False   \n",
       "ISRG  1.012360  1.015842  1.015842       True      True     True       False   \n",
       "TROW  1.019398  1.019575  1.019575       True      True     True       False   \n",
       "NLSN  1.000000  1.000000  1.000000      False     False    False       False   \n",
       "...        ...       ...       ...        ...       ...      ...         ...   \n",
       "ECL   1.020098  1.022426  1.022426       True      True     True       False   \n",
       "EBAY  1.028219  1.027660  1.027660       True      True     True       False   \n",
       "SBUX  1.059919  1.060984  1.060984       True      True     True       False   \n",
       "DPZ   1.022884  1.022898  1.022898       True      True     True       False   \n",
       "DRE   0.999999  1.000000  1.000000      False     False    False        True   \n",
       "\n",
       "      LSTM_SELL  RNN_SELL  BUY_SELL  \n",
       "UAL       False     False  3.103214  \n",
       "NVR       False     False  3.063736  \n",
       "ISRG      False     False  3.044043  \n",
       "TROW      False     False  3.058549  \n",
       "NLSN      False     False  3.000000  \n",
       "...         ...       ...       ...  \n",
       "ECL       False     False  3.064950  \n",
       "EBAY      False     False  3.083538  \n",
       "SBUX      False     False  3.181887  \n",
       "DPZ       False     False  3.068680  \n",
       "DRE       False     False  2.999999  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b951c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f6f6e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARIMA</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>RNN</th>\n",
       "      <th>ARIMA_BUY</th>\n",
       "      <th>LSTM_BUY</th>\n",
       "      <th>RNN_BUY</th>\n",
       "      <th>ARIMA_SELL</th>\n",
       "      <th>LSTM_SELL</th>\n",
       "      <th>RNN_SELL</th>\n",
       "      <th>BUY_SELL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UEEC</th>\n",
       "      <td>1.125762</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.365762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LVS</th>\n",
       "      <td>1.119109</td>\n",
       "      <td>1.115436</td>\n",
       "      <td>1.115436</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.349982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBUX</th>\n",
       "      <td>1.059919</td>\n",
       "      <td>1.060984</td>\n",
       "      <td>1.060984</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.181887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HCA</th>\n",
       "      <td>1.057630</td>\n",
       "      <td>1.049237</td>\n",
       "      <td>1.049237</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.156105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CF</th>\n",
       "      <td>1.043112</td>\n",
       "      <td>1.042698</td>\n",
       "      <td>1.042698</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.128507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPG</th>\n",
       "      <td>1.011343</td>\n",
       "      <td>1.013847</td>\n",
       "      <td>1.013847</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.039037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDLZ</th>\n",
       "      <td>1.012547</td>\n",
       "      <td>1.012976</td>\n",
       "      <td>1.012976</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.038498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GILD</th>\n",
       "      <td>1.012774</td>\n",
       "      <td>1.012043</td>\n",
       "      <td>1.012043</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.036860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MO</th>\n",
       "      <td>1.011019</td>\n",
       "      <td>1.011041</td>\n",
       "      <td>1.011041</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS-PJ</th>\n",
       "      <td>1.003913</td>\n",
       "      <td>1.004166</td>\n",
       "      <td>1.004166</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.012244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ARIMA      LSTM       RNN  ARIMA_BUY  LSTM_BUY  RNN_BUY  ARIMA_SELL  \\\n",
       "UEEC   1.125762  1.120000  1.120000       True      True     True       False   \n",
       "LVS    1.119109  1.115436  1.115436       True      True     True       False   \n",
       "SBUX   1.059919  1.060984  1.060984       True      True     True       False   \n",
       "HCA    1.057630  1.049237  1.049237       True      True     True       False   \n",
       "CF     1.043112  1.042698  1.042698       True      True     True       False   \n",
       "...         ...       ...       ...        ...       ...      ...         ...   \n",
       "PPG    1.011343  1.013847  1.013847       True      True     True       False   \n",
       "MDLZ   1.012547  1.012976  1.012976       True      True     True       False   \n",
       "GILD   1.012774  1.012043  1.012043       True      True     True       False   \n",
       "MO     1.011019  1.011041  1.011041       True      True     True       False   \n",
       "GS-PJ  1.003913  1.004166  1.004166       True      True     True       False   \n",
       "\n",
       "       LSTM_SELL  RNN_SELL  BUY_SELL  \n",
       "UEEC       False     False  3.365762  \n",
       "LVS        False     False  3.349982  \n",
       "SBUX       False     False  3.181887  \n",
       "HCA        False     False  3.156105  \n",
       "CF         False     False  3.128507  \n",
       "...          ...       ...       ...  \n",
       "PPG        False     False  3.039037  \n",
       "MDLZ       False     False  3.038498  \n",
       "GILD       False     False  3.036860  \n",
       "MO         False     False  3.033100  \n",
       "GS-PJ      False     False  3.012244  \n",
       "\n",
       "[95 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Composite_DayTrade = Composite[Composite['ARIMA'] > 1]\n",
    "Composite_DayTrade = Composite_DayTrade[Composite_DayTrade['LSTM'] > 1]\n",
    "Composite_DayTrade = Composite_DayTrade[Composite_DayTrade['RNN'] > 1]\n",
    "Composite_DayTrade = Composite_DayTrade.sort_values(by=['BUY_SELL'], ascending=False)\n",
    "Composite_DayTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7917f2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c21a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef7fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e6a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a493b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1876ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473eaf96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb034b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f995a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9ee31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9869a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d65849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40dd56e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
